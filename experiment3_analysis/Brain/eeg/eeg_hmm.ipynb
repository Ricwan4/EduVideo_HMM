{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1075d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "from pathlib import Path\n",
    "\n",
    "from modules import preproc, rhino, source_recon, parcellation, hmm, utils\n",
    "import mne\n",
    "from osl_dynamics import inference, analysis\n",
    "from osl_dynamics.utils import plotting\n",
    "from osl_dynamics.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing and source reconstruction\n",
    "for subj_id in [f\"{i:02d}\" for i in range(1, 34)]:\n",
    "    for task_id in [f\"{i:02d}\" for i in range(1, 7)]:\n",
    "\n",
    "        out_id = f\"sub-{subj_id}_ses-01_task-stim{task_id}\"\n",
    "\n",
    "        try:\n",
    "            if not os.path.exists(f'prep_data/sub-{subj_id}_ses-01_task-stim{task_id}_eeg.fif'):\n",
    "                print(f\"[skip]: {f'prep_data/sub-{subj_id}_ses-01_task-stim{task_id}_eeg.fif'}\")\n",
    "                continue\n",
    "            fns = utils.OSLFilenames(\n",
    "                outdir=\"out_data\",\n",
    "                id=out_id,\n",
    "                preproc_file=f\"prep_data/sub-{subj_id}_ses-01_task-stim{task_id}_eeg.fif\",\n",
    "                surfaces_dir=\"mni152_surfaces\",  # replace with the 'outdir' used in rhino.extract_surfaces if you have your own structural\n",
    "            )\n",
    "\n",
    "            rhino.extract_polhemus_from_fif(fns, include_eeg_as_headshape=True)\n",
    "            rhino.coregister(\n",
    "                fns,\n",
    "                allow_smri_scaling=True,  # set to False if using a real structural\n",
    "            )\n",
    "\n",
    "            rhino.forward_model(fns, model=\"Triple Layer\", gridstep=8, meg=False, eeg=True)\n",
    "\n",
    "            fif_file = f\"prep_data/sub-{subj_id}_ses-01_task-stim{task_id}_eeg.fif\"\n",
    "            raw = mne.io.read_raw_fif(fif_file, preload=False)\n",
    "\n",
    "            source_recon.lcmv_beamformer(fns, raw, chantypes=\"eeg\", rank={\"eeg\": 50})\n",
    "            voxel_data, voxel_coords = source_recon.apply_lcmv_beamformer(fns, raw)\n",
    "\n",
    "            parcellation_file = \"fmri_d100_parcellation_with_PCC_reduced_2mm_ss5mm_ds8mm.nii.gz\"\n",
    "\n",
    "            parcel_data = parcellation.parcellate(\n",
    "                fns,\n",
    "                voxel_data,\n",
    "                voxel_coords,\n",
    "                method=\"spatial_basis\",\n",
    "                orthogonalisation=\"symmetric\",\n",
    "                parcellation_file=parcellation_file,\n",
    "            )\n",
    "\n",
    "            parcellation.save_as_fif(\n",
    "                parcel_data,\n",
    "                raw,\n",
    "                extra_chans=\"stim\",\n",
    "                filename=f\"out_data/{out_id}/lcmv-parc-raw.fif\",\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[error] {out_id} with: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6892475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = \"/out_data\"\n",
    "\n",
    "# loop range\n",
    "subj_range = range(1, 33) \n",
    "task_range = range(1, 7)\n",
    "target_file_name = \"lcmv-parc-raw.fif\"\n",
    "# -----------------------\n",
    "\n",
    "fif_files = []\n",
    "for s in subj_range:\n",
    "    subj_id = f\"{s:02d}\"\n",
    "        \n",
    "    for t in task_range:\n",
    "        task_id = f\"{t:02d}\"\n",
    "        out_id = f\"sub-{subj_id}_ses-01_task-stim{task_id}\"\n",
    "        file_path = os.path.join(base_dir, out_id, target_file_name)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            fif_files.append(file_path)\n",
    "\n",
    "data = Data(\n",
    "    fif_files, \n",
    "    picks=\"misc\", \n",
    "    reject_by_annotation=\"omit\", \n",
    "    n_jobs=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b2b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"prepared_data.pkl\",'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d001e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hmm.prepare_data_for_canonical_hmm(data, parcellation=\"38ROI_Giles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "472bff32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 13:13:15.889528: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597363bdc099421e8e224c4d278b1dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting alpha:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 13:13:20.192046: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2026-01-02 13:13:20.699824: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2026-01-02 13:13:21.562670: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2026-01-02 13:13:23.386104: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2026-01-02 13:13:26.777529: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2026-01-02 13:13:33.861781: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2026-01-02 13:13:48.061253: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2026-01-02 13:14:16.434735: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "model = hmm.load_canonical_hmm(n_states=6, parcellation=\"38ROI_Giles\")\n",
    "# State probability time course\n",
    "alp = model.get_alpha(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbc27ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "n_states = 6\n",
    "n_sessions = len(alp)\n",
    "all_fo = np.zeros([n_sessions,n_states])\n",
    "all_lt =np.zeros([n_sessions,n_states])\n",
    "all_intv = np.zeros([n_sessions,n_states])\n",
    "all_sr = np.zeros([n_sessions,n_states])\n",
    "\n",
    "\n",
    "column_names = []\n",
    "\n",
    "for i in range(n_sessions):\n",
    "    current_alp = alp[i]\n",
    "    current_fif = fif_files[i]\n",
    "    \n",
    "    session_id = current_fif.split('/')[-2]\n",
    "    column_names.append(session_id)\n",
    "    \n",
    "    alp_raw = inference.modes.convert_to_mne_raw(current_alp, current_fif, n_embeddings=data.n_embeddings, verbose=False)\n",
    "    fs = alp_raw.info[\"sfreq\"]\n",
    "    \n",
    "    # HMM features\n",
    "    stc = inference.modes.argmax_time_courses(current_alp)\n",
    "    all_fo[i,:] = analysis.post_hoc.fractional_occupancies(stc)\n",
    "    all_lt[i,:] = analysis.post_hoc.mean_lifetimes(stc, sampling_frequency=fs)\n",
    "    all_intv[i,:] = analysis.post_hoc.mean_intervals(stc, sampling_frequency=fs)\n",
    "    all_sr[i,:] = analysis.post_hoc.switching_rates(stc, sampling_frequency=fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c21e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "n_states = 6\n",
    "n_sessions = len(alp)\n",
    "all_fo = np.zeros([n_sessions,n_states])\n",
    "all_lt =np.zeros([n_sessions,n_states])\n",
    "all_intv = np.zeros([n_sessions,n_states])\n",
    "all_sr = np.zeros([n_sessions,n_states])\n",
    "\n",
    "\n",
    "column_names = []\n",
    "\n",
    "for i in range(n_sessions):\n",
    "    current_alp = alp[i]\n",
    "    current_fif = fif_files[i]\n",
    "    \n",
    "    session_id = current_fif.split('/')[-2]\n",
    "    column_names.append(session_id)\n",
    "    \n",
    "    alp_raw = inference.modes.convert_to_mne_raw(current_alp, current_fif, n_embeddings=data.n_embeddings, verbose=False)\n",
    "    fs = alp_raw.info[\"sfreq\"]\n",
    "    \n",
    "    # HMM features\n",
    "    stc = inference.modes.argmax_time_courses(current_alp)\n",
    "    all_fo[i,:] = analysis.post_hoc.fractional_occupancies(stc)\n",
    "    all_lt[i,:] = analysis.post_hoc.mean_lifetimes(stc, sampling_frequency=fs)\n",
    "    all_intv[i,:] = analysis.post_hoc.mean_intervals(stc, sampling_frequency=fs)\n",
    "    all_sr[i,:] = analysis.post_hoc.switching_rates(stc, sampling_frequency=fs)\n",
    "\n",
    "# Export\n",
    "state_labels = [f\"State {j}\" for j in range(n_states)]\n",
    "\n",
    "df_fo = pd.DataFrame(all_fo)\n",
    "df_lt = pd.DataFrame(all_lt)\n",
    "df_intv = pd.DataFrame(all_intv)\n",
    "df_sr = pd.DataFrame(all_sr)\n",
    "df_fo.to_csv(\"HMM_FO.csv\")\n",
    "df_lt.to_csv(\"HMM_Lifetimes.csv\")\n",
    "df_intv.to_csv(\"HMM_Intervals.csv\")\n",
    "df_sr.to_csv(\"HMM_SwitchingRates.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e644305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcellation = \"38ROI_Giles\"\n",
    "n_states=6\n",
    "plots_dir = f\"plots/{n_states}_states_{parcellation}\"\n",
    "hmm.plot_canonical_group_level_networks(n_states=n_states, parcellation=parcellation, plots_dir=plots_dir)\n",
    "hmm.display_network_plots(n_states=n_states, plots_dir=plots_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "style_mapping = {\n",
    "    'stim01': 'Style1', 'stim02': 'Style1',\n",
    "    'stim03': 'Style2', 'stim04': 'Style2',\n",
    "    'stim05': 'Style3', 'stim06': 'Style3'\n",
    "}\n",
    "\n",
    "data_store = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for i in range(len(fif_files)):\n",
    "    current_alp = alp[i]\n",
    "    current_fif = fif_files[i]\n",
    "    \n",
    "    session_id = current_fif.split('/')[-2]\n",
    "    \n",
    "    parts = session_id.split('_')\n",
    "    sub_id = parts[0]  # 'sub-1'\n",
    "    stim_id = parts[-1].split('-')[-1]  # 'stim01'\n",
    "    \n",
    "    style_label = style_mapping.get(stim_id)\n",
    "    \n",
    "    if style_label:\n",
    "        stc = inference.modes.argmax_time_courses(current_alp)\n",
    "        data_store[sub_id][style_label].append(stc)\n",
    "\n",
    "results = []\n",
    "subjects = sorted(data_store.keys())\n",
    "\n",
    "for sub in subjects:\n",
    "    sub_row = {'Subject': sub}\n",
    "    for style in ['Style1', 'Style2', 'Style3']:\n",
    "        stclist = data_store[sub].get(style, [])\n",
    "        \n",
    "        if len(stclist) > 0:\n",
    "            combined_stc = np.concatenate(stclist, axis=0) \n",
    "            fo = np.mean(combined_stc, axis=0) \n",
    "        else:\n",
    "            fo = np.full(6, np.nan)\n",
    "        \n",
    "        for state_idx in range(6):\n",
    "            col_name = f'State{state_idx+1}_{style}'\n",
    "            sub_row[col_name] = fo[state_idx]\n",
    "            \n",
    "    results.append(sub_row)\n",
    "\n",
    "df_final = pd.DataFrame(results).set_index('Subject')\n",
    "df_final.to_csv('FO_results_by_style.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
